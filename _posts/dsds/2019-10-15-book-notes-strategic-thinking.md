---
id: qa5XMhnj7UOn9pyhljktT
title: 'Book Notes: Strategic Thinking'
desc: ''
updated: 1636922485903
created: 1636922485903
date: '2019-10-15'
categories:
  - research
---

Strategic Thinking

Strategic thinking is the art of outdoing an adversary, knowing that the adversary is trying to do the same to you.

Knowing how well your football team can pass or run, and how well the other team can defend against each choice, your decision as the coach is whether to pass or to run. Sometimes, as in the case of superpowers contemplating an adventure that risks nuclear war, strategic thinking also means knowing when not to play.

Risky innovations are their best and perhaps only chance of gaining market share. This is true not just of high-technology goods. Proctor and Gamble, the IBM of diapers, followed Kimberly Clark’s innovation of resealable diaper tape, and recaptured its commanding market position. There are two ways to move second. You can imitate as soon as the other has revealed his approach (as in sailboat racing) or wait longer until the success or failure of the approach is known (as in computers).

We usually refer to the players in a game as “opponents,” but you should remember that on occasion, strategy makes strange bedfellows.

Intransigence: refusing to compromise or agree

De Gaulle judged his position carefully to ensure that it would be accepted. But that often left the larger (and unfair) division of the spoils to France. De Gaulle’s intransigence denied the other party an opportunity to come back with a counteroffer that was acceptable. In practice, this is easier said than done, for two kinds of reasons. The first kind stems from the fact that bargaining usually involves considerations beside the pie on today’s table. The perception that you have been excessively greedy may make others less willing to negotiate with you in the future. Or, next time they may be more firm bargainers as they try to recapture some of their perceived losses. On a personal level, an unfair win may spoil business relations, or even personal relations. Indeed, biographer David Schoenbrun faulted de Gaulle’s chauvinism: “In human relations, those who do not love are rarely loved: those who will not be friends end up by having none. De Gaulle’s rejection of friendship thus hurt France.”5 A compromise in the short term may prove a better strategy over the long haul. The second kind of problem lies in achieving the necessary degree of intransigence. Luther and de Gaulle achieved this through their personalities. But this entails a cost. An inflexible personality is not something you can just turn on and off. Although being inflexible can sometimes wear down an opponent and force him to make concessions, it can equally well allow small losses to grow into major disasters. Ferdinand de Lesseps was a mildly competent engineer with extraordinary vision and determination. He is famous for building the Suez Canal in what seemed almost impossible conditions. He did not recognize the impossible and thereby accomplished it. Later, he tried using the same technique to build the Panama Canal. It ended in disaster.\* Whereas the sands of the Nile yielded to his will, tropical malaria did not. The problem for de Lesseps was that his inflexible personality could not admit defeat even when the battle was lost. How can one achieve selective inflexibility?

The United Auto Workers have a similar advantage when they negotiate with the auto manufacturers sequentially. A strike against Ford alone puts it at particular disadvantage when General Motors and Chrysler continue to operate; therefore Ford is more likely to settle quickly on terms favorable to the Union. Such a strike is also less costly to the Union as only one third of their members are out. After winning against Ford, the Union takes on GM and then Chrysler, using each previous success as precedent and fuel for their fire. In contrast, Japanese union incentives work the other way, since they are organized by company and have more profit sharing. If the Toyota unions strike, their members’ incomes suffer along with Toyota’s profits and they gain nothing from the precedent effect.

namely, an “accordion effect,” where each fold pushes or pulls the next.

Economists have estimated that when import quotas are used to protect industries such as steel, textiles, or sugar, the rest of us pay higher prices amounting to roughly $100,000 for each job saved.6 How is it that the gains to a few always get priority over the much larger aggregate losses to the many? The trick is to bring up the cases one at a time. First, 10,000 jobs in the shoe industry are at risk. To save them would cost a billion dollars to the rest of us, or just over $4 each. Who wouldn’t agree to pay $4 to save 10,000 jobs even for total strangers, especially when nasty foreigners can be blamed for their plight? Then along comes the garment industry, the steel industry, the auto industry, and so on. Before we know it, we have agreed to pay over $50 billion, which is more than $200 each, or nearly $1,000 per family.

Let us return for a moment to the world of sports. In football, before each snap of the ball the offense chooses between passing and running while the defense organizes itself to counter one of these plays. In tennis, the server might go to the forehand or the backhand of the receiver, while the receiver, in turn, can try to return crosscourt or down the line. In these examples, each side has an idea of its own strong points and of its opponent’s weaknesses. It will have a preference for the choice that exploits these weaknesses, but not exclusively. It is well understood, by players and sports fans alike, that one should mix one’s plays, randomly throwing in the unexpected move. The point is that if you do the same thing all the time, the opposition will be able to counter you more effectively by concentrating its resources on the best response to your one strategy.

He claimed that it would be impossible to get from there to here for that amount. Before negotiations could continue, he locked all the doors automatically and retraced the route at breakneck speed, ignoring traffic lights and pedestrians. Were they being kidnapped to Beirut? No. He returned to the original position and ungraciously kicked the two economists out of his cab, yelling, “See how far your 2,200 shekels will get you now.” They found another cab. This driver turned on his meter, and 2,200 shekels later they were home. Certainly the extra time was not worth the 300 shekels to the economists. On the other hand, the story was well worth it. It illustrates the dangers of bargaining with those who have not yet read our book. More generally, pride and irrationality cannot be ignored. Sometimes, it may be better to be taken for a ride when it costs only two dimes.† There is a second lesson to the story. Think of how much stronger their bargaining position would have been if they had begun to discuss the price after getting out of the taxi.

When it came time for the last spin of the roulette wheel, by a happy coincidence, Barry led with $700 worth of chips, and the next closest was a young Englishwoman, with $300. The rest of the group had been effectively cleaned out. Just before the last bets were to be placed, the woman offered to split next year’s ball ticket, but Barry refused. With his substantial lead, there was little reason to settle for half. To better understand the next strategic move, we take a brief detour to the rules of roulette. The betting in roulette is based on where a ball will land when the spinning wheel stops. There are typically numbers 0 through 36 on the wheel. When the ball lands on zero, the house wins. The safest bet in roulette is to bet on even or odd (denoted by Black or Red). These bets pay even money—a one-dollar bet returns two dollars—while the chance of winning is only 18/37. Even betting her entire stake would not lead to victory at these odds; therefore, the woman was forced to take one of the more risky gambles. She bet her entire stake on the chance that the ball would land on a multiple of three. This bet pays two to one (so her $300 bet would return $900 if she won) but has only a 12/37 chance of winning. She placed her bet on the table. At that point it could not be withdrawn. What should Barry have done? Barry should have copied the woman’s bet and placed $300 on the event that the ball landed on a multiple of three. This guarantees that he stays ahead of her by $400 and wins the ticket: either they both lose the bet and Barry wins $400 to $0, or they both win the bet and Barry ends up ahead $1,300 to $900. The woman had no other choice. If she did not bet, she would have lost anyway; whatever she bet on, Barry could follow her and stay ahead.\* Her only hope was that Barry would bet first. If Barry had been first to place $200 on Black, what should she have done? She should have bet her $300 on Red. Betting her stake on Black would do her no good, since she would win only when Barry wins (and she would place second with $600 compared with Barry’s $900). Winning when Barry lost would be her only chance to take the lead, and that dictates a bet on Red. The strategic moral is the opposite from that of our tale of Martin Luther and Charles de Gaulle. In this tale of roulette, the person who moved first was at a disadvantage. The woman, by betting first, allowed Barry to choose a strategy that would guarantee victory. If Barry had bet first, the woman could have chosen a response that offered an even chance of winning. The general point is that in games it is not always an advantage to seize the initiative and move first. This reveals your hand, and the other players can use this to their advantage and your cost. Second movers may be in the stronger strategic position.

The essence of a game of strategy is the interdependence of the players’ decisions. These interactions arise in two ways. The first is sequential, as in the Charlie Brown story. The players make alternating moves. Each player, when it is his turn, must look ahead to how his current actions will affect the future actions of others, and his own future actions in turn. The second kind of interaction is simultaneous, as in the prisoners’ dilemma.

Rule 1: Look ahead and reason back.

The right way to use such a map or tree is not to take the route whose first branch looks best and then “cross the Verrazano Bridge when you get to it.” Instead, you anticipate the future decisions and use them to make your earlier choices.

For any game with a finite number of sequential moves there exists some best strategy.

One of the general morals from this story is that if you have to take some risks, it is often better to do this as quickly as possible. This is obvious to those who play tennis: everyone knows to take risks on the first serve and hit the second serve more cautiously. That way, if you fail on your first attempt, the game won’t be over. You may still have time to take some other options that can bring you back to or even ahead of where you were.

Although this scene adds excitement, it is somewhat embarrassing (to us) that such a distinguished professor as Dr. Indiana Jones would overlook his dominant strategy. He should have given the water to his father without testing it first. If Indiana has chosen the right cup, his father is still saved. If Indiana has chosen the wrong cup, then his father dies but Indiana is spared. Testing the cup before giving it to his father doesn’t help, since if Indiana has made the wrong choice, there is no second chance—Indiana dies from the water and his father dies from the wound.\*

Finding dominant strategies is considerably easier than the search for the Holy Grail. Consider Alfred, Lord Tennyson’s familiar line: “Tis better to have loved and lost than never to have loved at all.”1 In other words, love is a dominant strategy.

Another instance of this process occurred in the area of international trade policy. Tariffs are the most visible tools for restricting trade, and successive rounds of negotiations of the General Agreement on Tariffs and Trade (GATT) achieved large mutual reductions of tariff rates of all industrial countries. But each country still had its domestic political pressures from powerful special interests to restrict imports. Therefore countries gradually switched to other, less visible means, such as voluntary restraint agreements, customs valuation procedures, standards, administrative practices, and complicated quotas. The common theme of these examples is that collusion focuses on the more transparent dimensions of choice, and competition shifts to the less observable ones: we call this the Law of Increasing Opaqueness.

Behind every good scheme to encourage cooperation is usually some mechanism to punish cheaters. A prisoner who confesses and implicates his collaborators may become the target of revenge by the others’ friends. The prospect of getting out of prison more quickly may look less alluring given the knowledge of what waits outside. Police have been known to scare drug dealers into confessing by threatening to release them. The threat is that if they are released, their suppliers will assume they have squealed.

When Robert Campeau made his first bid for Federated Stores (and its crown jewel, Bloomingdales), he used the strategy of a two-tiered tender offer. This case study looks at the effectiveness of the two-tiered bid as a strategic move: does it give the raider an unfair advantage?

A two-tiered bid typically offers a high price to the first shares tendered and a lower price to the later shares tendered. To keep numbers simple, we look at a case in which the pre-takeover price is $100 per share. The first tier of the bid offers a higher price, $105 per share to the first shareholders until half of the total shares are tendered. The next fifty percent of the shares tendered fall into the second tier; the price paid for these shares is only $90 per share. For fairness, shares are not placed in the different tiers based on the order in which they are tendered. Rather, everyone gets a blended price: all the shares tendered are placed on a prorated basis into the two-tiers. (Those who don’t tender find all of their shares end up in the second tier if the bid succeeds.)\* We can express the average payment for shares by a simple algebraic expression: if fewer than 50 percent tender, everyone gets $105 per share; if an amount X% ≥ 50% of the company’s total stock gets tendered, then the average price paid per share is

One thing to notice about the way the two-tiered offer is made is that it is unconditional; even if the raider does not get control, the tendered shares are still purchased at the first-tier price. The second feature to note about the way this two-tiered offer works is that if everyone tenders, then the average price per share is only $97.50. This is less than the price before the offer. It’s also worse than what they expect should the takeover fail; if the raider is defeated, shareholders expect the price to return to the $100 level. Hence they hope that the offer is defeated or that another raider comes along. In fact another raider did come along, namely Macy’s. Imagine that Macy’s makes a conditional tender offer: it offers $102 per share provided that it gets a majority of the shares. To whom do you tender and which (if either) offer do you expect to succeed? Case Discussion Tendering to the two-tiered offer is a dominant strategy. To verify this, we consider all the possible cases. There are three possibilities to check. The two-tiered offer attracts less than 50 percent of the total shares and fails. The two-tiered offer attracts some amount above 50 percent and succeeds. The two-tiered offer attracts exactly 50 percent. If you tender, the offer will succeed, and without you it fails. In the first case, the two-tiered offer fails, so that the post-tender price is either $100 if both offers fail or $102 if the competing offer succeeds. But if you tender you get $105 per share, which is bigger than either alternative. In the second case, if you don’t tender you get only $90 per share. Tendering gives you at worst $97.50. So again it is better to tender. In the third case, while other people are worse off if the offer succeeds, you are privately better off. The reason is that since there are exactly 50 percent tendered, you will be getting $105 per share. This is worthwhile. Thus you are willing to push the offer over. Because tendering is a dominant strategy, we expect everyone to tender. When everyone tenders, the average blended price per share may be below the pre-bid price and even below the expected future price should the offer fail. Hence the two-tiered bid enables a raider to pay less than the company is worth.

A game is a situation of strategic interdependence: the outcome of your choices (strategies) depends upon the choices of another person or persons acting purposively. The decision-makers involved in a game are called players, and their choices are called moves. The interests of the players in a game may be in strict conflict; one person’s gain is always another’s loss. Such games are called zero-sum. But more typically, there are zones of commonality of interests as well as of conflict; there can be combinations of mutually gainful or mutually harmful strategies. Nevertheless, we usually refer to the other players in a game as one’s rivals. The moves in a game may be sequential or simultaneous. In a game of sequential moves, there is a linear chain of thinking: If I do this, my rival can do that, and in turn I can respond in the following way…. Such a game is studied by drawing the game tree. The best choices of moves can be found by applying Rule 1: Look forward, and reason backward. In a game with simultaneous moves, there is a logical circle of reasoning: I think that he thinks that I think that…. This circle must be squared; one must see through the rival’s action even though one cannot see it when making one’s own move. To tackle such a game, construct a table that shows the outcomes corresponding to all conceivable combinations of choices. Then proceed in the following steps. Begin by seeing if either side has a dominant strategy—one that outperforms all of that side’s other strategies, irrespective of the rival’s choice. This leads to Rule 2: If you have a dominant strategy, use it. If you don’t have a dominant strategy, but your rival does, then count on his using it, and choose your best response accordingly. Next, if neither side has a dominant strategy, see if either has a dominated strategy—one that is uniformly worse for the side playing it than another of its strategies. If so, apply Rule 3: Eliminate dominated strategies from consideration. Go on doing so successively. If during the process any dominant strategies emerge in the smaller games, they should be chosen successively. If this procedure ends in a unique outcome, you have found the prescriptions of action for the players and the outcome of the game. Even if the procedure does not lead to a unique outcome, it can reduce the size of the game to a more manageable level. Finally, if there are neither dominant nor dominated strategies, or after the game has been simplified as far as possible using the second step, apply Rule 4: Look for an equilibrium, a pair of strategies in which each player’s action is the best response to the other’s. If there is a unique equilibrium of this kind, there are good arguments why all players should choose it. If there are many such equilibria, one needs a commonly understood rule or convention for choosing one over the others. If there is no such equilibrium, that usually means that any systematic behavior can be exploited by one’s rivals, and therefore indicates the need for mixing one’s plays. In practice, games can have some sequential moves and some simultaneous moves; then a combination of these techniques must be employed to think about and determine one’s best choice of actions.

To sum up, there is no solution that achieves reciprocal cooperation in a one-time game. Only in an ongoing relationship is there an ability to punish, and thus a stick to motivate cooperation. A collapse of cooperation carries an automatic cost in the form of a loss of future profits. If this cost is large enough, cheating will be deterred and cooperation sustained. There are some caveats to this general principle. The first arises when the relationship has some natural end, such as the end of a term in an elected office. In these situations, the game is repeated only a fixed number of times. Using the principle of looking ahead and reasoning back, we see that cooperation must end when there is no longer any time left to punish. Yet neither wants to be left cooperating while the other cheats. If ever someone cooperates, then someone must get stuck in the end. Since neither is willing to play the fool, cooperation never gets started. This is true no matter how long the game is, provided the end is known. Let us look at this argument a little more carefully. Right from the start, both players should look ahead to predict the last play. On this last play, there will be no future to consider, and the dominant strategy is to cheat. The outcome of the last play is a foregone conclusion. Since there is no way to affect the last play of the game, the penultimate play effectively becomes the last one to consider. Once again, cheating is a dominant strategy. The reason is that the play in the next-to-last period has no effect on the strategies chosen in the final period. Thus the penultimate period can be considered in isolation. For any period in isolation, cheating is a dominant strategy. Now the play of the final two periods can be taken as given. Cooperating early on won’t help, as both players are resigned to cheat in the final two periods. Hence, the third-to-last period is effectively the last one to consider. The same argument applies and cheating is a dominant strategy. This argument unwinds all the way back, so that there is no cooperation even in the first play. The logic of this argument is impeccable, and yet in the real world we find episodes of successful cooperation. There are various ways to explain this. One is that all actual games of this kind are repeated only a finite number of times, but that number is unknown. Since there is no fixed last time, there is always the possibility that the relationship will go on. Then the players have some incentive to sustain the cooperation for the sake of such future contingencies; if this incentive is large enough, the cooperation will persist.
